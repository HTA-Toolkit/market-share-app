import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

# ==========================================
# 1. æ ¸å¿ƒç®—æ³•å®šä¹‰
# ==========================================

def predict_proportional_model_simple(df, target_drug, new_share_target):
    """ä¼ ç»Ÿç­‰æ¯”ä¾‹æŸå¤±æ³•"""
    df = df.dropna(subset=['å½“å‰ä»½é¢']).copy()
    target_row = df[df['å“ç‰Œ'] == target_drug]
    if target_row.empty: return pd.Series(dtype=float)

    s_x_old = target_row['å½“å‰ä»½é¢'].values[0]
    delta_s_x = new_share_target - s_x_old
    
    other_drugs = df[df['å“ç‰Œ'] != target_drug].copy()
    sum_s_i_old = other_drugs['å½“å‰ä»½é¢'].sum()
    
    if sum_s_i_old == 0:
        other_drugs['predicted_share'] = 0
    else:
        other_drugs['predicted_share'] = other_drugs['å½“å‰ä»½é¢'] - delta_s_x * (other_drugs['å½“å‰ä»½é¢'] / sum_s_i_old)
    
    other_drugs['predicted_share'] = other_drugs['predicted_share'].apply(lambda x: max(0, x))
    result = other_drugs.set_index('å“ç‰Œ')['predicted_share']
    result[target_drug] = new_share_target
    return result

def predict_logit_model_simple(df, target_drug, new_share_target):
    """ä¼ ç»Ÿ Logit æ³•"""
    df = df.dropna(subset=['å½“å‰ä»½é¢', 'æŒ‡æ•°æ•ˆç”¨å€¼']).copy()
    remaining_share = 1.0 - new_share_target
    other_drugs = df[df['å“ç‰Œ'] != target_drug].copy()
    
    other_drugs['weight'] = other_drugs['å½“å‰ä»½é¢'] * other_drugs['æŒ‡æ•°æ•ˆç”¨å€¼']
    total_weight = other_drugs['weight'].sum()
    
    if total_weight == 0:
        if other_drugs['å½“å‰ä»½é¢'].sum() > 0:
            other_drugs['predicted_share'] = remaining_share * (other_drugs['å½“å‰ä»½é¢'] / other_drugs['å½“å‰ä»½é¢'].sum())
        else:
            other_drugs['predicted_share'] = 0
    else:
        other_drugs['predicted_share'] = remaining_share * (other_drugs['weight'] / total_weight)
        
    result = other_drugs.set_index('å“ç‰Œ')['predicted_share']
    result[target_drug] = new_share_target
    return result

def predict_bayesian_replacement(df, target_drug, new_share_target):
    """ã€è®ºæ–‡æ ‡å‡†ç‰ˆã€‘è´å¶æ–¯ç®—æ³•: Likelihood = Ui / (Ui + Ux)"""
    return predict_bayesian_custom(df, target_drug, new_share_target, formula_str="Ui / (Ui + Ux)")

def predict_bayesian_custom(df, target_drug, new_share_target, formula_str):
    """
    ã€è‡ªå®šä¹‰ç‰ˆã€‘è´å¶æ–¯ç®—æ³•
    å…è®¸ç”¨æˆ·è¾“å…¥ Likelihood çš„è®¡ç®—å…¬å¼ã€‚
    """
    df = df.dropna(subset=['å½“å‰ä»½é¢', 'æŒ‡æ•°æ•ˆç”¨å€¼']).copy()
    
    target_row = df[df['å“ç‰Œ'] == target_drug]
    if target_row.empty: return pd.Series(dtype=float), None
    
    Ux = target_row['æŒ‡æ•°æ•ˆç”¨å€¼'].values[0]
    Px = target_row['å¹´æ²»ç–—è´¹ç”¨(å…ƒ)'].values[0]
    
    other_drugs = df[df['å“ç‰Œ'] != target_drug].copy()
    
    likelihoods = []
    try:
        for index, row in other_drugs.iterrows():
            Ui = row['æŒ‡æ•°æ•ˆç”¨å€¼']
            Pi = row['å¹´æ²»ç–—è´¹ç”¨(å…ƒ)']
            Si = row['å½“å‰ä»½é¢']
            
            # å®‰å…¨æ‰§è¡Œå…¬å¼
            val = eval(formula_str, {"__builtins__": None}, {
                "Ui": Ui, "Ux": Ux, 
                "Pi": Pi, "Px": Px, 
                "Si": Si, "np": np
            })
            likelihoods.append(max(0.0, float(val)))
            
        other_drugs['Likelihood'] = likelihoods
        
    except Exception as e:
        st.error(f"å…¬å¼è§£æå¤±è´¥: {e}")
        return pd.Series(dtype=float), None

    other_drugs['Posterior_Numerator'] = other_drugs['å½“å‰ä»½é¢'] * other_drugs['Likelihood']
    denominator = other_drugs['Posterior_Numerator'].sum()
    remaining_share = 1.0 - new_share_target
    
    if denominator == 0:
        sum_orig = other_drugs['å½“å‰ä»½é¢'].sum()
        if sum_orig > 0:
            other_drugs['predicted_share'] = remaining_share * (other_drugs['å½“å‰ä»½é¢'] / sum_orig)
        else:
            other_drugs['predicted_share'] = 0
    else:
        other_drugs['predicted_share'] = remaining_share * (other_drugs['Posterior_Numerator'] / denominator)
    
    result = other_drugs.set_index('å“ç‰Œ')['predicted_share']
    result[target_drug] = new_share_target
    
    return result, other_drugs[['å“ç‰Œ', 'Likelihood']]

# ==========================================
# 2. é¡µé¢å¸ƒå±€ä¸äº¤äº’è®¾è®¡
# ==========================================

st.set_page_config(page_title="åŸºäºDCEæŒ‡æ•°æ•ˆç”¨å€¼å¸‚åœºä»½é¢é¢„æµ‹å™¨", layout="wide", page_icon="ğŸ§¬")

st.title("ğŸ§¬ åŸºäºDCEæŒ‡æ•°æ•ˆç”¨å€¼å¸‚åœºä»½é¢é¢„æµ‹å™¨ ")
st.markdown("""
æœ¬å·¥å…·åŸºäº **è´å¶æ–¯æ¨æ–­æ¡†æ¶**ï¼Œé€šè¿‡å®šä¹‰ **ä¼¼ç„¶å‡½æ•° (Likelihood)** æ¥æ¨¡æ‹Ÿç«å“åœ¨é¢å¯¹æ–°äº§å“å†²å‡»æ—¶çš„ä¿ç•™æ¦‚ç‡ã€‚
æ”¯æŒä½¿ç”¨é¢„è®¾æ ‡å‡†ç®—æ³•ï¼Œæˆ–è‡ªå®šä¹‰ä¼¼ç„¶é€»è¾‘ã€‚
""")

# --- Sidebar ---
with st.sidebar:
    st.header("âš™ï¸ å˜é‡è¯å…¸")
    st.markdown("""
    åœ¨è‡ªå®šä¹‰å…¬å¼ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å˜é‡ï¼š
    - **`Ui`**: ç«å“ $i$ çš„æŒ‡æ•°æ•ˆç”¨å€¼
    - **`Ux`**: ç›®æ ‡äº§å“ $x$ çš„æŒ‡æ•°æ•ˆç”¨å€¼
    - **`Pi`**: ç«å“ $i$ çš„å¹´è´¹ç”¨
    - **`Px`**: ç›®æ ‡äº§å“ $x$ çš„å¹´è´¹ç”¨
    - **`Si`**: ç«å“ $i$ çš„å½“å‰ä»½é¢
    - **`np`**: Numpyæ•°å­¦åº“
    """)

# --- Step 1: æ•°æ®å½•å…¥ ---
st.subheader("1. å¸‚åœºæ•°æ®åˆå§‹åŒ–")

# å®šä¹‰æ ‡å‡†åˆ—å
REQUIRED_COLUMNS = ['å“ç‰Œ', 'å½“å‰ä»½é¢', 'æŒ‡æ•°æ•ˆç”¨å€¼', 'å¹´æ²»ç–—è´¹ç”¨(å…ƒ)']

# 1. æ£€æŸ¥ Session State ä¸­çš„æ•°æ®æ˜¯å¦åˆæ³• (æ˜¯å¦ç¼ºå¤±å…³é”®åˆ—)
# å¦‚æœæ˜¯æ—§ç¼“å­˜å¯¼è‡´çš„æ•°æ®ä¸ä¸€è‡´ï¼Œå¼ºåˆ¶é‡ç½®
need_reset = False
if 'init_df' not in st.session_state:
    need_reset = True
else:
    # æ£€æŸ¥å½“å‰å†…å­˜ä¸­çš„ df æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…é¡»çš„åˆ—
    existing_cols = st.session_state.init_df.columns.tolist()
    if not all(col in existing_cols for col in REQUIRED_COLUMNS):
        need_reset = True

# 2. å¦‚æœéœ€è¦ï¼Œåˆå§‹åŒ–/é‡ç½®æ•°æ®
if need_reset:
    data = {
        'å“ç‰Œ': ['è‡ªå®¶äº§å“', 'ç«å“A', 'ç«å“B', 'ç«å“C'],
        'å½“å‰ä»½é¢': [0.54, 0.22, 0.19, 0.05], 
        'æŒ‡æ•°æ•ˆç”¨å€¼': [2.58, 0.88, 1.41, 0.50], 
        'å¹´æ²»ç–—è´¹ç”¨(å…ƒ)': [6000, 8000, 7500, 5000]
    }
    st.session_state.init_df = pd.DataFrame(data)
    # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥åº”ç”¨é‡ç½®
    st.rerun()

col1, col2 = st.columns([2, 1])
with col1:
    edited_df = st.data_editor(
        st.session_state.init_df,
        num_rows="dynamic", # å…è®¸æ·»åŠ æ–°è¡Œ
        column_config={
            "å½“å‰ä»½é¢": st.column_config.NumberColumn(format="%.2f", min_value=0, max_value=1),
            "æŒ‡æ•°æ•ˆç”¨å€¼": st.column_config.NumberColumn(label="æŒ‡æ•°æ•ˆç”¨å€¼(U)", min_value=0.01),
            "å¹´æ²»ç–—è´¹ç”¨(å…ƒ)": st.column_config.NumberColumn(format="ï¿¥%d")
        },
        use_container_width=True
    ).fillna(0) # å¡«å……æ–°åŠ è¡Œçš„ç©ºå€¼ä¸º0

    # ã€å…³é”®ä¿®å¤ã€‘è¿‡æ»¤æ‰æ–°åŠ è¡Œä¸­â€œå“ç‰Œâ€ä¸ºç©ºçš„æ•°æ®ï¼Œé˜²æ­¢åç»­æŠ¥é”™
    # åªæœ‰å½“å“ç‰Œåä¸ä¸ºç©ºï¼Œä¸”ä¸ä¸º0æ—¶ï¼Œæ‰è§†ä¸ºæœ‰æ•ˆæ•°æ®
    edited_df = edited_df[edited_df['å“ç‰Œ'].astype(str).str.strip() != '0']
    edited_df = edited_df[edited_df['å“ç‰Œ'].astype(str).str.strip() != '']
    edited_df = edited_df[edited_df['å“ç‰Œ'].notna()]

total_share = edited_df['å½“å‰ä»½é¢'].sum()
with col2:
    st.metric("å½“å‰å¸‚åœºæ€»ä»½é¢", f"{total_share:.1%}")
    if not (0.99 <= total_share <= 1.01):
        st.error("âš ï¸ ä»½é¢æ€»å’Œå¿…é¡»ç­‰äº 100%")
        st.stop()
    else:
        st.success("âœ… æ ¡éªŒé€šè¿‡")

   
# --- Step 2: è®¾å®šç›®æ ‡ ---
st.divider()
st.subheader("2. è®¾å®šé¢„æµ‹æƒ…æ™¯")

if edited_df.empty: st.stop()

c1, c2 = st.columns(2)
with c1:
    target_product = st.selectbox("é€‰æ‹©ç›®æ ‡äº§å“ (x)", options=edited_df['å“ç‰Œ'])
    tgt_row = edited_df[edited_df['å“ç‰Œ']==target_product]
    curr_share = tgt_row['å½“å‰ä»½é¢'].values[0] if not tgt_row.empty else 0
    Ux_val = tgt_row['æŒ‡æ•°æ•ˆç”¨å€¼'].values[0] if not tgt_row.empty else 1.0

with c2:
    new_share_input = st.slider(
        f"è®¾å®š {target_product} çš„æ–°å¸‚åœºä»½é¢",
        0.0, 1.0, float(min(1.0, curr_share + 0.1)), 0.01
    )

st.write("---")
st.subheader("3. é€‰æ‹©é¢„æµ‹ç®—æ³•")

algo_type = st.radio(
    "é€‰æ‹©ä¼¼ç„¶å‡½æ•° (Likelihood Function) çš„å®šä¹‰æ–¹å¼ï¼š",
    ["åŸºäºDCEæŒ‡æ•°æ•ˆç”¨å€¼æ¨¡å¼ (Ui / (Ui + Ux))", 
     "è‡ªå®šä¹‰æ¨¡å¼ (ç¼–å†™Pythonè¡¨è¾¾å¼)", 
     "ä¼ ç»Ÿç­‰æ¯”ä¾‹æŸå¤±", 
     "ä¼ ç»Ÿå¤šé¡¹ Logit"],
    index=0
)

# --- è‡ªå®šä¹‰å…¬å¼åŒºåŸŸ ---
custom_formula = "Ui / (Ui + Ux)" # é»˜è®¤å€¼

if algo_type == "è‡ªå®šä¹‰æ¨¡å¼ (ç¼–å†™Pythonè¡¨è¾¾å¼)":
    # åˆ›å»ºä¸¤åˆ—ï¼Œå·¦è¾¹è¾“å…¥ï¼Œå³è¾¹æ”¾ä¸€ç‚¹æç¤º
    col_f1, col_f2 = st.columns([2, 1])
    
    with col_f1:
        custom_formula = st.text_input(
            "è¾“å…¥ Python è¡¨è¾¾å¼ (è¿”å›ä¼¼ç„¶æ¦‚ç‡)", 
            value="Ui / (Ui + Ux)"
        )
    
    with col_f2:
        st.info("ğŸ’¡ è®°å¾—ä½¿ç”¨ sidebar ä¸­çš„å˜é‡å (Ui, Ux, Pi...)")

    # --- è¿™é‡Œæ˜¯ä½ è¦çš„æ–°å¢éƒ¨åˆ†ï¼šä½¿ç”¨æŠ˜å é¢æ¿æä¾›è¯¦ç»†æŒ‡å— ---
    with st.expander("ğŸ“– å¦‚ä½•ä½¿ç”¨â€œè‡ªå®šä¹‰ä¼¼ç„¶å‡½æ•°â€ï¼Ÿ(ç‚¹å‡»å±•å¼€é«˜çº§æŒ‡å—)"):
        st.markdown("""
        ### ğŸ§  ä»€ä¹ˆæ˜¯â€œä¼¼ç„¶å‡½æ•°â€ (Likelihood)?
        åœ¨è´å¶æ–¯æ¡†æ¶ä¸‹ï¼Œ`Likelihood` ä»£è¡¨ **â€œåœ¨é¢å¯¹ç›®æ ‡äº§å“ x çš„å†²å‡»æ—¶ï¼Œç«å“ i ä¿ç•™ä½ä»½é¢çš„æ¦‚ç‡â€**ã€‚
        - ç»“æœæ¥è¿‘ **1.0**: ç«å“é˜²å¾¡åŠ›å¼ºï¼Œå‡ ä¹ä¸æµå¤±ä»½é¢ã€‚
        - ç»“æœæ¥è¿‘ **0.0**: ç«å“é˜²å¾¡åŠ›å¼±ï¼Œä»½é¢å¤§é‡æµå¤±ç»™æ–°äº§å“ã€‚

        ### ğŸ“ å¸¸ç”¨å…¬å¼ç¤ºä¾‹ (å¯ç›´æ¥å¤åˆ¶åˆ°è¾“å…¥æ¡†)

        **1. è®ºæ–‡æ ‡å‡†æ¨¡å‹ (åŸºäºæ•ˆç”¨)**
        - **å…¬å¼**: `Ui / (Ui + Ux)`
        - **å«ä¹‰**: åŸºäºDCEæŒ‡æ•°æ•ˆç”¨å€¼æ¨¡å‹ã€‚ä»…çœ‹æ•ˆç”¨å¯¹æ¯”ï¼Œæ•ˆç”¨è¶Šé«˜ï¼Œä¿ç•™æ¦‚ç‡è¶Šå¤§ã€‚

        **2. æ€§ä»·æ¯”æ¨¡å‹ (Cost-Effectiveness)**
        - **å…¬å¼**: `(Ui/Pi) / ((Ui/Pi) + (Ux/Px))` æˆ– `(Pi/Ui) / ((Pi/Ui) + (Px/Ux))`
        - **å«ä¹‰**: å‡è®¾åŒ»ç”Ÿå†³ç­–æ˜¯åŸºäºâ€œæ¯å…ƒé’±ä¹°åˆ°çš„ç–—æ•ˆâ€æˆ–â€œå•ä½æ•ˆç”¨å€¼æˆæœ¬â€ã€‚å¦‚æœç«å“æ€§ä»·æ¯”(U/P)æ›´é«˜æˆ–å•ä½æ•ˆç”¨æˆæœ¬(P/U)æ›´ä½ï¼Œåˆ™æ›´å®¹æ˜“ä¿ç•™ã€‚

        **3. ä»·æ ¼æ•æ„Ÿæ¨¡å‹ (çº¯ä»·æ ¼é˜²å¾¡)**
        - **å…¬å¼**: `(1/Pi) / ((1/Pi) + (1/Px))`
        - **å«ä¹‰**: å‡è®¾å¸‚åœºå¯¹ä»·æ ¼æåº¦æ•æ„Ÿã€‚ä»·æ ¼è¶Šä½(1/Pè¶Šå¤§)ï¼Œä¿ç•™æ¦‚ç‡è¶Šé«˜ã€‚

        **4. èµ¢å®¶é€šåƒæ¨¡å‹ (Winner Takes All)**
        - **å…¬å¼**: `1.0 if Ui >= Ux else 0.0`
        - **å«ä¹‰**: æ¿€è¿›å‡è®¾ã€‚åªè¦ç«å“æ•ˆç”¨æ¯”æ–°è¯é«˜ï¼Œä¸€ç‚¹ä»½é¢éƒ½ä¸ä¸¢ï¼›åªè¦æ¯”æ–°è¯ä½ï¼Œåœ¨è¯¥è½®ç«äº‰ä¸­å…¨éƒ¨æµå¤±ã€‚
        """)

# --- Step 3: è®¡ç®—ä¸å±•ç¤º ---
st.divider()

if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
    
    likelihood_data = None
    
    if "è®ºæ–‡æ ‡å‡†" in algo_type:
        result_series, likelihood_data = predict_bayesian_replacement(edited_df, target_product, new_share_input)
    elif "è‡ªå®šä¹‰" in algo_type:
        result_series, likelihood_data = predict_bayesian_custom(edited_df, target_product, new_share_input, custom_formula)
    elif "ç­‰æ¯”ä¾‹" in algo_type:
        result_series = predict_proportional_model_simple(edited_df, target_product, new_share_input)
    else:
        result_series = predict_logit_model_simple(edited_df, target_product, new_share_input)
        
    if result_series.empty:
        st.stop()

    # ç»“æœæ•´åˆ
    result_df = edited_df.copy()
    result_df['é¢„æµ‹æ–°ä»½é¢'] = result_df['å“ç‰Œ'].map(result_series).fillna(0)
    result_df['ä»½é¢å˜åŒ–'] = result_df['é¢„æµ‹æ–°ä»½é¢'] - result_df['å½“å‰ä»½é¢']
    
    if likelihood_data is not None:
        result_df = result_df.merge(likelihood_data, on='å“ç‰Œ', how='left')
        result_df.loc[result_df['å“ç‰Œ']==target_product, 'Likelihood'] = np.nan

    # KPI
    kpi1, kpi2, kpi3 = st.columns(3)
    kpi1.metric(f"{target_product} æ–°ä»½é¢", f"{new_share_input:.1%}", f"{(new_share_input - curr_share):.1%}")
    cost_diff = (result_df['é¢„æµ‹æ–°ä»½é¢']*result_df['å¹´æ²»ç–—è´¹ç”¨(å…ƒ)']).sum() - \
                (result_df['å½“å‰ä»½é¢']*result_df['å¹´æ²»ç–—è´¹ç”¨(å…ƒ)']).sum()
    kpi2.metric("äººå‡æ²»ç–—è´¹ç”¨å˜åŒ–", f"ï¿¥{cost_diff:+,.0f}")
    
    competitors = result_df[result_df['å“ç‰Œ']!=target_product]
    if not competitors.empty:
        loser = competitors.sort_values('ä»½é¢å˜åŒ–').iloc[0]
        kpi3.metric("å—å†²å‡»æœ€å¤§ç«å“", f"{loser['å“ç‰Œ']}", f"{loser['ä»½é¢å˜åŒ–']:.1%}")

    # å¯è§†åŒ–
    tab1, tab2 = st.tabs(["ğŸ“Š ç»“æœå›¾è¡¨", "ğŸ“‹ è¯¦ç»†æ•°æ®ä¸ä¼¼ç„¶éªŒè¯"])
    
    with tab1:
        c_chart1, c_chart2 = st.columns(2)
        with c_chart1:
            plot_df = result_df[['å“ç‰Œ', 'å½“å‰ä»½é¢', 'é¢„æµ‹æ–°ä»½é¢']].melt(id_vars='å“ç‰Œ')
            fig = px.bar(plot_df, x='å“ç‰Œ', y='value', color='variable', barmode='group', text_auto='.1%')
            st.plotly_chart(fig, use_container_width=True)
        with c_chart2:
            fig_w = go.Figure(go.Waterfall(
                x=result_df['å“ç‰Œ'], y=result_df['ä»½é¢å˜åŒ–'],
                text=[f"{v:+.1%}" for v in result_df['ä»½é¢å˜åŒ–']],
                measure=["relative"]*len(result_df)
            ))
            fig_w.update_layout(title="ä»½é¢å‡€å˜åŒ– (Waterfall)")
            st.plotly_chart(fig_w, use_container_width=True)

    with tab2:
        st.markdown(f"**å½“å‰ä½¿ç”¨çš„ç®—æ³•/å…¬å¼:** `{algo_type if 'è‡ªå®šä¹‰' not in algo_type else custom_formula}`")
        if likelihood_data is not None:
            st.caption("Likelihood è¶Šå¤§ï¼Œè¯´æ˜ç«å“é˜²å¾¡åŠ›è¶Šå¼ºï¼Œè¶Šéš¾è¢«ç›®æ ‡äº§å“å–ä»£ã€‚")
            
        fmt_dict = {
            'å½“å‰ä»½é¢': '{:.2%}', 'é¢„æµ‹æ–°ä»½é¢': '{:.2%}', 'ä»½é¢å˜åŒ–': '{:+.2%}',
            'æŒ‡æ•°æ•ˆç”¨å€¼': '{:.2f}', 'å¹´æ²»ç–—è´¹ç”¨(å…ƒ)': 'ï¿¥{:,.0f}'
        }
        if "Likelihood" in result_df.columns:
            fmt_dict['Likelihood'] = '{:.2%}'
            
        st.dataframe(result_df.style.format(fmt_dict).background_gradient(subset=['ä»½é¢å˜åŒ–'], cmap='RdYlGn'))
